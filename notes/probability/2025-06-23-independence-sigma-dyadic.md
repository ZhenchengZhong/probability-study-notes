# Study Notes: Independence, Ïƒ-fields and Dyadic Approximation

Date: 2025-06-23  
Textbook: Probability and Measure by Patrick Billingsley (3rd ed.)  
Section: p56-p60  

---

> **Note**:  
> Today's focus is on understanding independence from Ïƒ-field perspective and the dyadic representation of Ï‰ âˆˆ [0,1), including approximation error and run-length interpretation.

## Content logic

- Corollary 2 explores independence of rows in an array of events {A_ij}, and shows how Ïƒ-fields generated by rows are independent under certain structural assumptions.
- The key idea is to build Ï€-systems from each row and apply Corollary 1 after showing joint independence through product measures.
- The notion of information is formalized through Ïƒ-fields, with A-equivalence (Ï‰ â‰¡ Ï‰â€² if they agree on all A âˆˆ ğ’œ) leading to the idea that Ïƒ(ğ’œ)-partitions the sample space into informationally indistinct classes.
- In Example 4.10, an apparent paradox is addressed: a Ïƒ-field ğ’¢ may contain â€œallâ€ information in one heuristic sense and yet be independent from a given event in the formal sense. This illustrates the limits of treating Ïƒ-fields purely as information carriers.
- Borelâ€“Cantelli Lemma 1 (Theorem 4.3) is introduced and used to derive almost sure bounds on run lengths in binary expansions.

## Key Ideas

- Independence of Ïƒ-fields can be constructed via Ï€-systems and finite product decompositions, as shown in Corollary 2.
- The concept of partial information aligns with sub-Ïƒ-fields: knowing I_A(Ï‰) for all A in ğ’œ is akin to knowing which partition cell Ï‰ belongs to.
- The Borelâ€“Cantelli Lemma provides a bridge between convergence of probabilities and almost sure event behavior, especially in sequences of events like A_n = {l_n(Ï‰) â‰¥ r_n}.
- The run length l_n(Ï‰), i.e., the number of leading 0â€™s after position n in the binary expansion of Ï‰, can be used to bound dyadic approximation error.

## Proof Sketch

- In Theorem 4.3, if âˆ‘ P(A_n) < âˆ, then P(limsup A_n) = 0. This is proved by tail bounding:  
  P(â‹ƒ_{k=m}^âˆ A_k) â‰¤ âˆ‘_{k=m}^âˆ P(A_k), which â†’ 0 as m â†’ âˆ.
- Example 4.11 applies this lemma to show that if âˆ‘ 1/2^{r_n} < âˆ, then the event {l_n(Ï‰) â‰¥ r_n i.o.} has probability 0.
- Choosing r_n = (1 + Îµ) logâ‚‚ n gives a convergence condition, leading to:
  
  P(Ï‰ : l_n(Ï‰)/logâ‚‚ n > 1 i.o.) = 0  
  P(Ï‰ : limsup l_n(Ï‰)/logâ‚‚ n â‰¤ 1) = 1

- This establishes a typical run-length growth rate, almost surely bounded by logâ‚‚ n.

## Dyadic Approximation Error

- For Ï‰ âˆˆ [0,1), truncating its binary expansion after n-1 digits gives:

  âˆ‘_{k=1}^{n-1} (1 / 2^k) d_k(Ï‰)

- The actual error (normalized) is defined as:

  e_n(Ï‰) = (Ï‰ - âˆ‘_{k=1}^{n-1} d_k(Ï‰)/2^k) / 2^{-n+1}  
         = âˆ‘_{i=1}^âˆ d_{n+i-1}(Ï‰) / 2^i

- The value of e_n(Ï‰) lies in (0,1), and its binary expansion begins with l_n(Ï‰) many 0's followed by a 1, so:

  1 / 2^{l_n(Ï‰)+1} â‰¤ e_n(Ï‰) â‰¤ 1 / 2^{l_n(Ï‰)}

- This shows how the number of leading zeros (run length) directly controls the approximation error in the dyadic system.

## Reflections

- The interpretation of Ïƒ-fields as â€œinformationâ€ is compelling but should be handled cautiously. While heuristic reasoning is helpful, formal independence is based on measure-theoretic properties, not intuition.
- The run-length and approximation error connection offers a fascinating bridge between symbolic binary expansions and probability.
- The Borelâ€“Cantelli lemma continues to be a powerful tool to characterize almost sure events, especially in the context of digital expansions and convergence speed.
- The transition from raw approximation error to a normalized version (e_n(Ï‰)) is subtle but crucial. It allows easier comparative analysis across scales.

