# Study Notes: Independence, σ-fields and Dyadic Approximation

Date: 2025-06-23  
Textbook: Probability and Measure by Patrick Billingsley (3rd ed.)  
Section: p56-p60  

---

> **Note**:  
> Today's focus is on understanding independence from σ-field perspective and the dyadic representation of ω ∈ [0,1), including approximation error and run-length interpretation.

## Content logic

- Corollary 2 explores independence of rows in an array of events {A_ij}, and shows how σ-fields generated by rows are independent under certain structural assumptions.
- The key idea is to build π-systems from each row and apply Corollary 1 after showing joint independence through product measures.
- The notion of information is formalized through σ-fields, with A-equivalence (ω ≡ ω′ if they agree on all A ∈ 𝒜) leading to the idea that σ(𝒜)-partitions the sample space into informationally indistinct classes.
- In Example 4.10, an apparent paradox is addressed: a σ-field 𝒢 may contain “all” information in one heuristic sense and yet be independent from a given event in the formal sense. This illustrates the limits of treating σ-fields purely as information carriers.
- Borel–Cantelli Lemma 1 (Theorem 4.3) is introduced and used to derive almost sure bounds on run lengths in binary expansions.

## Key Ideas

- Independence of σ-fields can be constructed via π-systems and finite product decompositions, as shown in Corollary 2.
- The concept of partial information aligns with sub-σ-fields: knowing I_A(ω) for all A in 𝒜 is akin to knowing which partition cell ω belongs to.
- The Borel–Cantelli Lemma provides a bridge between convergence of probabilities and almost sure event behavior, especially in sequences of events like A_n = {l_n(ω) ≥ r_n}.
- The run length l_n(ω), i.e., the number of leading 0’s after position n in the binary expansion of ω, can be used to bound dyadic approximation error.

## Proof Sketch

- In Theorem 4.3, if ∑ P(A_n) < ∞, then P(limsup A_n) = 0. This is proved by tail bounding:  
  P(⋃_{k=m}^∞ A_k) ≤ ∑_{k=m}^∞ P(A_k), which → 0 as m → ∞.
- Example 4.11 applies this lemma to show that if ∑ 1/2^{r_n} < ∞, then the event {l_n(ω) ≥ r_n i.o.} has probability 0.
- Choosing r_n = (1 + ε) log₂ n gives a convergence condition, leading to:
  
  P(ω : l_n(ω)/log₂ n > 1 i.o.) = 0  
  P(ω : limsup l_n(ω)/log₂ n ≤ 1) = 1

- This establishes a typical run-length growth rate, almost surely bounded by log₂ n.

## Dyadic Approximation Error

- For ω ∈ [0,1), truncating its binary expansion after n-1 digits gives:

  ∑_{k=1}^{n-1} (1 / 2^k) d_k(ω)

- The actual error (normalized) is defined as:

  e_n(ω) = (ω - ∑_{k=1}^{n-1} d_k(ω)/2^k) / 2^{-n+1}  
         = ∑_{i=1}^∞ d_{n+i-1}(ω) / 2^i

- The value of e_n(ω) lies in (0,1), and its binary expansion begins with l_n(ω) many 0's followed by a 1, so:

  1 / 2^{l_n(ω)+1} ≤ e_n(ω) ≤ 1 / 2^{l_n(ω)}

- This shows how the number of leading zeros (run length) directly controls the approximation error in the dyadic system.

## Reflections

- The interpretation of σ-fields as “information” is compelling but should be handled cautiously. While heuristic reasoning is helpful, formal independence is based on measure-theoretic properties, not intuition.
- The run-length and approximation error connection offers a fascinating bridge between symbolic binary expansions and probability.
- The Borel–Cantelli lemma continues to be a powerful tool to characterize almost sure events, especially in the context of digital expansions and convergence speed.
- The transition from raw approximation error to a normalized version (e_n(ω)) is subtle but crucial. It allows easier comparative analysis across scales.

